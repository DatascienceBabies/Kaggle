{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import collections\n",
    "import Dataset as ds\n",
    "import DatasetModifier as dsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter creation steps\n",
    "\n",
    "datasetModifier = dsm.DatasetModifier()\n",
    "datasetModifier.dataset_randomize()\n",
    "datasetModifier.dataset_fill_missing_number('Age', 30)\n",
    "datasetModifier.dataset_categorize_number('Age', [['infant', 0, 2], ['child', 2, 10], ['teenager', 10, 18], ['youngadult', 18, 30], ['midlife', 30, 50], ['oldfart', 50, math.inf]])\n",
    "datasetModifier.add_X_parameter('Age')\n",
    "datasetModifier.one_hot_X_parameter('Age')\n",
    "datasetModifier.add_X_parameter('Sex')\n",
    "datasetModifier.one_hot_X_parameter('Sex')\n",
    "datasetModifier.standardize_X()\n",
    "\n",
    "datasetModifier.add_Y_parameter('Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train/test dataset\n",
    "dataset = ds.Dataset()\n",
    "dataset.load_dataset_from_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age         177\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.find_null_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the prediction dataset\n",
    "dataset_prediction = ds.Dataset()\n",
    "dataset_prediction.load_dataset_from_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.find_null_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Apply the parameter creation steps to the two datasets\n",
    "datasetModifier.generate_X(dataset)\n",
    "datasetModifier.generate_Y(dataset)\n",
    "datasetModifier.generate_X(dataset_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X = dataset.get_X_train_test_sets(0.2)\n",
    "train_Y, test_Y = dataset.get_Y_train_test_sets(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the predict set data\n",
    "predict_X, _ = dataset_prediction.get_X_train_test_sets(0)\n",
    "test_passenger_ids = dataset_prediction.get_dataset_parameter('PassengerId')\n",
    "test_passenger_ids = np.reshape(test_passenger_ids.values, (test_passenger_ids.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7865168539325843\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "lr = LogisticRegressionCV(cv=7, random_state=0)\n",
    "lr.fit(train_X, train_Y)\n",
    "\n",
    "lr_score = lr.score(test_X, test_Y)\n",
    "print(lr_score)\n",
    "results[\"Logistic Regression\"] = {'score': lr_score,\n",
    "                     'model': lr}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Variations of SVM\n",
    "\n",
    "- Apply Grid Search Cross Validation to identify best Parameters (that might take a while depending on the number of steps...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def find_svm_params():\n",
    "\n",
    "    NUM_STEPS = 40\n",
    "\n",
    "    param_grid = {\n",
    "        'C': np.logspace(-3, 4, NUM_STEPS)\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(svm.SVC(gamma='auto'), param_grid, cv=7)\n",
    "    grid.fit(train_x, train_y)\n",
    "\n",
    "    print(grid.best_params_)\n",
    "    \n",
    "#find_svm_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7865168539325843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "svc_linear = svm.SVC(kernel='linear', C=2.5719138090593443)\n",
    "svc_linear.fit(train_X, train_Y)\n",
    "\n",
    "svc_linear_score = svc_linear.score(test_X, test_Y)\n",
    "print(svc_linear_score)\n",
    "\n",
    "results[\"SVC Linear\"] = {\n",
    "    'score': svc_linear_score,\n",
    "    'model': svc_linear\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_svm_kernel_params():\n",
    "    param_grid = {\n",
    "        'C': np.logspace(-3, 4, NUM_STEPS),\n",
    "        'gamma': np.logspace(-3, 4, NUM_STEPS),\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=7)\n",
    "    grid.fit(train_x, train_y)\n",
    "\n",
    "    print(grid.best_params_)\n",
    "    \n",
    "#find_svm_kernel_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7865168539325843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "svc_rbf = svm.SVC(kernel='rbf', gamma=0.04124626382901352, C=8.886238162743407)\n",
    "svc_rbf.fit(train_X, train_Y)\n",
    "\n",
    "svc_rbf_score = svc_rbf.score(test_X, test_Y)\n",
    "print(svc_rbf_score)\n",
    "\n",
    "results[\"SVC RBF\"] = {\n",
    "    'score': svc_rbf_score,\n",
    "    'model': svc_rbf\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7359550561797753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "naive_gauss = GaussianNB()\n",
    "naive_gauss.fit(train_X, train_Y)\n",
    "\n",
    "naive_gauss_score = naive_gauss.score(test_X, test_Y)\n",
    "print(naive_gauss_score)\n",
    "\n",
    "results[\"Naive Gauss\"] = {\n",
    "    'score': naive_gauss_score,\n",
    "    'model': naive_gauss\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Trees & Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7696629213483146\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(max_depth=6)\n",
    "\n",
    "clf.fit(train_X, train_Y)\n",
    "clf_score = clf.score(test_X, test_Y)\n",
    "print(clf_score)\n",
    "\n",
    "results[\"Classification Tree\"] = {\n",
    "    'score': clf_score,\n",
    "    'model': clf\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def random_search_for_params():\n",
    "    param_grid = {\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 7000, num = 10)],\n",
    "        'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'bootstrap': [True, False],\n",
    "    }\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = param_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    rf_random.fit(train_x, train_y)\n",
    "\n",
    "    print(rf_random.best_params_)\n",
    "    \n",
    "def grid_search_for_params():\n",
    "    param_grid = {\n",
    "        'max_features': ['auto'],\n",
    "        'n_estimators': [4000, 5000, 5500, 6000, 7000],\n",
    "        'max_depth': [5, 8, 10, 15, 20, 50],\n",
    "        'min_samples_split': [4, 5, 6],\n",
    "        'min_samples_leaf': [1],\n",
    "        'bootstrap': [True],\n",
    "    }\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "    rf_gridCV = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 3, verbose=2, n_jobs = -1)\n",
    "    rf_gridCV.fit(train_x, train_y)\n",
    "\n",
    "    print(rf_gridCV.best_params_)\n",
    "    \n",
    "#random_search_for_params()\n",
    "#grid_search_for_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7696629213483146\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(max_features='auto', max_depth=5, n_estimators=5000, min_samples_split=4, min_samples_leaf=1, bootstrap=True)\n",
    "rfc.fit(train_X, train_Y)\n",
    "\n",
    "rfc_score = rfc.score(test_X, test_Y)\n",
    "print(rfc_score)\n",
    "\n",
    "results[\"Random Forest\"] = {\n",
    "    'score': rfc_score,\n",
    "    'model': rfc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression scored 0.7865168539325843\n",
      "SVC Linear scored 0.7865168539325843\n",
      "SVC RBF scored 0.7865168539325843\n",
      "Naive Gauss scored 0.7359550561797753\n",
      "Classification Tree scored 0.7696629213483146\n",
      "Random Forest scored 0.7696629213483146\n",
      "Best Model is: Logistic Regression with a score of 0.7865168539325843 - will continue with this\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "\n",
    "for key in results:\n",
    "    model_name = key\n",
    "    score = results[key][\"score\"]\n",
    "    print(\"{0} scored {1}\".format(model_name, score))\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_model_name = model_name\n",
    "        best_model = results[key]['model']\n",
    "    \n",
    "print('Best Model is: {0} with a score of {1} - will continue with this'.format(best_model_name, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model against the test data\n",
    "predict_Y = lr.predict(predict_X)\n",
    "predict_Y = np.around(predict_Y)\n",
    "predict_Y = predict_Y.astype(np.integer)\n",
    "predict_Y = np.reshape(predict_Y, (predict_Y.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_predict = np.concatenate((test_passenger_ids, predict_Y), axis=1)\n",
    "csv_predict = np.concatenate((np.reshape([\"PassengerId\", \"Survived\"], (1, 2)), csv_predict))\n",
    "with open('prediction.csv', 'w', newline='') as csvFile:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerows(csv_predict)\n",
    "csvFile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
